{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv' does not exist: b'/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-34f966aa4aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Load Iris dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m## Store the target vaue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    695\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv' does not exist: b'/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "## Load Iris dataset\n",
    "df = pd.read_csv('/Users/rohith/Documents/Datasets/Iris_dataset/iris.csv') \n",
    "## Store the target vaue\n",
    "classes = df['Species']  \n",
    "## Drop the Id and Class values from dat\n",
    "df = df.drop(['Id','Species'],axis=1) \n",
    "## Convert dataframe into list and then into a numpy array\n",
    "data = df.values.tolist() \n",
    "data = np.array(data)\n",
    "## Shuffle classes and data \n",
    "data,classes = shuffle(data,classes) \n",
    "## First 135 points are used for training and the rest is used for testing\n",
    "train_data = data[:135]  \n",
    "test_data = data[135:]\n",
    "\n",
    "## K-Means Algorithm\n",
    "import random\n",
    "import numpy as np\n",
    "## Randomly place the centroids of the three clusters \n",
    "c1 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "c2 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "c3 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "## Intialize the number of iterations you want to run \n",
    "epochs = 1\n",
    "while(epochs <= 100):\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "    cluster_3 = []\n",
    "    for point in train_data:\n",
    "        ## Find the eucledian distance between all points the centroid\n",
    "        dis_point_c1 = ((c1[0]-point[0])**2 + (c1[1]-point[1])**2 + \n",
    "                        (c1[2]-point[2])**2 + (c1[3]-point[3])**2)**0.5\n",
    "        dis_point_c2 = ((c2[0]-point[0])**2 + (c2[1]-point[1])**2 + \n",
    "                        (c2[2]-point[2])**2 + (c2[3]-point[3])**2)**0.5\n",
    "        dis_point_c3 = ((c3[0]-point[0])**2 + (c3[1]-point[1])**2 + \n",
    "                        (c3[2]-point[2])**2 + (c3[3]-point[3])**2)**0.5\n",
    "        distances = [dis_point_c1,dis_point_c2,dis_point_c3]\n",
    "        ## Find the closest centroid to the point and assign the point to that cluster\n",
    "        pos = distances.index(min(distances))\n",
    "        if(pos == 0):\n",
    "            cluster_1.append(point)\n",
    "        elif(pos == 1):\n",
    "            cluster_2.append(point)\n",
    "        else:\n",
    "            cluster_3.append(point)\n",
    "    ## Store the centroid values to calculate new centroid values \n",
    "    prev_c1 = c1\n",
    "    prev_c2 = c2\n",
    "    prev_c3 = c3\n",
    "    cluster_1 = np.array(cluster_1)\n",
    "    cluster_2 = np.array(cluster_2)\n",
    "    cluster_3 = np.array(cluster_3)\n",
    "    ## Find mean of all points within a cluster and make it as the centroid \n",
    "    if(len(cluster_1) != 0):\n",
    "        c1 = [sum(cluster_1[:,0])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,1])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,2])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,3])/float(len(cluster_1))]\n",
    "    if(len(cluster_2) != 0):\n",
    "        c2 = [sum(cluster_2[:,0])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,1])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,2])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,3])/float(len(cluster_2))]\n",
    "    if(len(cluster_3) != 0):\n",
    "        c3 = [sum(cluster_3[:,0])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,1])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,2])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,3])/float(len(cluster_3))]\n",
    "    ## If centroid values hasn't changed, algorithm has convereged \n",
    "    if(prev_c1 == c1 and prev_c2 == c2 and prev_c3 == c3):\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    print(epochs)\n",
    "    epochs += 1\n",
    "\n",
    "    pred = []\n",
    "for point in test_data:\n",
    "    ## Find distance between test data point and centroids\n",
    "    dis_point_c1 = ((c1[0]-point[0])**2 + (c1[1]-point[1])**2 + \n",
    "                    (c1[2]-point[2])**2 + (c1[3]-point[3])**2)**0.5\n",
    "    dis_point_c2 = ((c2[0]-point[0])**2 + (c2[1]-point[1])**2 + \n",
    "                    (c2[2]-point[2])**2 + (c2[3]-point[3])**2)**0.5\n",
    "    dis_point_c3 = ((c3[0]-point[0])**2 + (c3[1]-point[1])**2 + \n",
    "                    (c3[2]-point[2])**2 + (c3[3]-point[3])**2)**0.5\n",
    "    ## Find the cluster to which the point is closest to and append \n",
    "    ## it to pred\n",
    "    distances = [dis_point_c1,dis_point_c2,dis_point_c3]\n",
    "    pos = distances.index(min(distances))\n",
    "    pred.append(pos)\n",
    "    ## Print the predictions \n",
    "    print(pred)\n",
    "    \n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "clf = KMeans(n_clusters = 3)\n",
    "clf.fit(train_data)\n",
    "pred = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-976255a08335>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-976255a08335>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    wget\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wget\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
